<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>LeetCode 1： 两数之和</title>
    <link href="undefined2019/12/03/LeetCode-1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/"/>
    <url>2019/12/03/LeetCode-1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/</url>
    
    <content type="html"><![CDATA[<h1 id="LeetCode-1：-两数之和"><a href="#LeetCode-1：-两数之和" class="headerlink" title="LeetCode 1： 两数之和"></a><div align="center">LeetCode 1： 两数之和</div></h1><h2 id="题目描述"><a href="#题目描述" class="headerlink" title="题目描述"></a>题目描述</h2><p>给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。</p><p>你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。</p><p><strong>示例:</strong><br> 给定$nums = [2, 7, 11, 15], target = 9$</p><p> 因为$nums[0] + nums[1] = 2 + 7 = 9$<br> 所以返回$[0, 1]$</p><h2 id="思想"><a href="#思想" class="headerlink" title="思想:"></a>思想:</h2><p>寻找$target-nums$，</p><h2 id="题解"><a href="#题解" class="headerlink" title="题解"></a>题解</h2><h3 id="暴力破解"><a href="#暴力破解" class="headerlink" title="暴力破解"></a>暴力破解</h3><ul><li>用两层循环，时间复杂度$o(n^2)$</li><li>使用List中相关函数，在每次循环中查找索引，本质上依然是$o(n^2)$的时间复杂度</li></ul><h4 id="solution1"><a href="#solution1" class="headerlink" title="solution1:"></a>solution1:</h4><p>在每次循环中顺序查找,但当出现重复数字时，第一次查找只会找到自身，只有第二次查找时才能得到结果。</p><p><strong>示例:</strong><br> 给定$nums = [3, 7, 11, 3], target = 6$</p><p> 只有第二次查找时，才会返回结果</p><pre><code class="python">def twoSum(nums, target):    for inx, num1 in enumerate(nums):        num2 = target - num1        if num2 in nums and nums.index(num2) != inx:            return [inx, nums.index(num2)]    return []</code></pre><h4 id="solution2"><a href="#solution2" class="headerlink" title="solution2:"></a>solution2:</h4><p>$num2$的查找并不需要每次从$nums$查找一遍，只需要从$num1$位置之前或之后查找即可。</p><pre><code class="python">def twoSum(nums, target):    for inx, num1 in enumerate(nums):        num2 = target - num1        temp = nums[:inx]        if num2 in temp:            return [nums.index(num2), inx]    return []</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>LeetCode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>点云笔记(一)：PointNet</title>
    <link href="undefined2019/12/02/%E7%82%B9%E4%BA%91%E7%AC%94%E8%AE%B0-%E4%B8%80-%EF%BC%9APointNet/"/>
    <url>2019/12/02/%E7%82%B9%E4%BA%91%E7%AC%94%E8%AE%B0-%E4%B8%80-%EF%BC%9APointNet/</url>
    
    <content type="html"><![CDATA[<h1 id="PointNet-Deep-Learning-on-Point-Sets-for-3D-Classification-and-Segmentation"><a href="#PointNet-Deep-Learning-on-Point-Sets-for-3D-Classification-and-Segmentation" class="headerlink" title="PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation"></a><div align="center">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</div></h1><h2 id="0-Summary"><a href="#0-Summary" class="headerlink" title="0. Summary"></a>0. Summary</h2><p>This paper proposes an end to end architecture to <strong><font color="#4b0082">directly consumes point clouds</font></strong>, which is well respect the <strong><font color="#4b0082">permutation invariance</font></strong> of the input points. It’s unified for applications ranging from object classification, part segmentation, to scene semantic parsing.</p><h2 id="1-Research-Objective"><a href="#1-Research-Objective" class="headerlink" title="1.Research Objective"></a>1.Research Objective</h2><p>Most works in deep learning focus on regular input representations like sequences, images and volumes, not much work has been done in deep learning on point sets. Those methods typically transform point sets data to regular 3D voxel grids or collections of images before feeding them to a deep net architecture. This data representation transformation renders the resulting data unnecessarily voluminous. <strong><font color="#4b0082">They are constrained by the representation power of the features extracted.</font></strong><br>To design a deep network directly consumes point sets, <strong><font color="#4b0082">invariance to permutations and to rigid motions</font></strong> are be considered.</p><h2 id="2-Problem-Statement"><a href="#2-Problem-Statement" class="headerlink" title="2.Problem Statement"></a>2.Problem Statement</h2><ul><li>Input: a set of 3D points  $\langle P_i|i=1,2,…,n\rangle$, $P_i$ is a vector of $(x,y,z)$ coordinate.</li><li>Output: $k$ scores for all the $k$ candidate classes.</li></ul><h2 id="3-Architecture"><a href="#3-Architecture" class="headerlink" title="3.Architecture"></a>3.Architecture</h2><h3 id="1-Unified-Architecture"><a href="#1-Unified-Architecture" class="headerlink" title="(1) Unified Architecture"></a><font color="#0099ff">(1) Unified Architecture</font></h3> <div align="center">![PointNet Architecture](http://i2.tiimg.com/705034/10a8394cf3f988d8.png)</div><ul><li><p><strong>Joint Alignment Network</strong><br>Predict  an affine transformation matrix by a mini-network(T-net) and directly apply this transformation to the coordinates of input points and features extracted.<br>To decrease the difficulty of optimizition, this paper add a regularization term to softmax training loss. The feature transform matrix is constrained to be close to orthogonal matrix:$$L_{reg}=||I-AA^T||^2_F$$</p></li><li><p><strong>Symmetry Function for Unordered Input</strong><br>There are three strategies:</p><ol><li>Sort input into a canonical order;</li><li>Theat the input as a sequence to train an RNN, augment the training data by all kinds of permutations;</li><li>Use a simple symmetric function to aggregate the information from each point: <strong><font color="#4b0082">Max pooling</font></strong></li></ol></li><li><p><strong>Local and Global Information Aggregation</strong><br>Global features can easily satisfy the classification task. However, point segmentation requires a combination of local and global knowledge.<br>Feed global feature back and concatenate it with each of the point features to construct new per point features</p></li></ul><h3 id="2-Part-Segmentation-Architecture"><a href="#2-Part-Segmentation-Architecture" class="headerlink" title="(2) Part Segmentation Architecture"></a><font color="#0099ff">(2) Part Segmentation Architecture</font></h3> <div align="center">![PointNet Part Segment](http://i2.tiimg.com/705034/02d226ecfc86fdcd.png)</div><ul><li><strong><font color="#4b0082">Add one-hot vector</font></strong> indicating the class of the input to segment all categoties in one time.</li></ul><h2 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4.Conclusion"></a>4.Conclusion</h2><p>This paper proposes a novel deep neural network to derectly consumes point cloud, using max pooling as symmetry function to maintain the permutation invariance.</p><h2 id="5-Notes"><a href="#5-Notes" class="headerlink" title="5.Notes"></a>5.Notes</h2><ul><li><p>Shared mlp represents the convolution layer, which is weight-shared and local connected.</p></li><li><p>When set input transform matrix with 4*4, which allows rotation along any axis, scale and translation transformation, the net can perform better.</p></li><li><p>Input point features for segmentation are concatenated by local point features and global features. While the sizes of local features are $$[64, 128, 128, 512, 2048, 2048, 16]$$which result new point features with <font color="#4b0082">$4944$</font></p></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="undefined2019/12/01/hello-world/"/>
    <url>2019/12/01/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>